{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdM9KHPaRNmD",
        "outputId": "cf238a59-f6b6-4379-c9d6-c8259e352a49"
      },
      "source": [
        "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "!tar -xf  simple-examples.tgz\n",
        "!mkdir data\n",
        "!mv /content/simple-examples/data/ptb.train.txt data/\n",
        "!mv /content/simple-examples/data/ptb.valid.txt data/\n",
        "!mv /content/simple-examples/data/ptb.test.txt data/\n",
        "!rm -rf ./simple_examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-21 07:16:52--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  2.84MB/s    in 13s     \n",
            "\n",
            "2021-03-21 07:17:06 (2.60 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B71K5lC_Xnyg",
        "outputId": "17329c3f-8cb2-4683-8b1d-f211c8d655e5"
      },
      "source": [
        "!pip install transformers\n",
        "!wget https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "--2021-03-21 08:07:29--  https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.92.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.92.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209850483 (200M) [application/json]\n",
            "Saving to: ‘personachat_self_original.json’\n",
            "\n",
            "personachat_self_or 100%[===================>] 200.13M  45.2MB/s    in 4.8s    \n",
            "\n",
            "2021-03-21 08:07:35 (41.3 MB/s) - ‘personachat_self_original.json’ saved [209850483/209850483]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S5ZszffTUhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c9dad4-a0d2-4403-971e-ddce71f37f5b"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EncoderDecoderModel, BertTokenizer, BertModel, BertConfig\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVUFk1dqSTbG"
      },
      "source": [
        "SPECIAL_TOKENS = [\"<bos>\", \"<eos>\", \"<persona>\", \"<speaker1>\", \"<speaker2>\", \"<pad>\"]\n",
        "\n",
        "ATTR_TO_SPECIAL_TOKEN = {'bos_token': '<bos>', 'eos_token': '<eos>', 'pad_token': '<pad>',\n",
        "                         'additional_special_tokens': ['<speaker1>', '<speaker2>', '<persona>']}\n",
        "\n",
        "def read_data(data_json_path='/content/personachat_self_original.json'):\n",
        "  with open(data_json_path) as json_file:\n",
        "    data_dict = json.load(json_file)\n",
        "  return data_dict\n",
        "\n",
        "def data_to_samples(data_dict, test=False):\n",
        "  samples=[]\n",
        "  for dialogue in (data_dict['train'] if test==False else data_dict['valid']):\n",
        "    original_persona = dialogue['personality']\n",
        "    \n",
        "    for item in dialogue['utterances']:\n",
        "      original_persona = [original_persona[-1]] + original_persona[:-1]\n",
        "      history = item['history']\n",
        "      response = item['candidates'][-1]\n",
        "      samples.append({\n",
        "          'persona':original_persona,\n",
        "          'history':history,\n",
        "          'response':response\n",
        "      })\n",
        "  return samples\n",
        "  \n",
        "def bertified(samples):\n",
        "  bertified_data = []\n",
        "  for item in samples:\n",
        "    persona = ' <persona> '.join(item['persona'])\n",
        "    persona = '<bos> ' + persona\n",
        "    history = ''\n",
        "    speakers = [\" <speaker1> \", \" <speaker2> \"]\n",
        "    speaker = 0\n",
        "    for hst in item['history'][::-1]:\n",
        "      history = speakers[speaker] + hst + history\n",
        "      speaker = 1 - speaker\n",
        "    response = '<speaker2> ' + item['response'] + ' <eos>'\n",
        "    bertified_data.append({\n",
        "          'persona':persona.replace('  ', ' '),\n",
        "          'history':history.replace('  ', ' '),\n",
        "          'input': persona.replace('  ', ' ')+' '+history.replace('  ', ' '), \n",
        "          'response':response.replace('  ', ' ')\n",
        "      })\n",
        "  return bertified_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iV8XBcrRTcQ"
      },
      "source": [
        "class PersonaDataset_v1(Dataset):\n",
        "  '''\n",
        "      Convert Data to proper Tensor dataset\n",
        "  '''\n",
        "  def __init__(self, samples):\n",
        "    self.samples = samples\n",
        "    self.n_samples = len(self.samples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # returns specific item\n",
        "    return self.samples[index] \n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "    # returns dataset length\n",
        "\n",
        "\n",
        "class PTBDataset(Dataset):\n",
        "  '''\n",
        "      Convert Data to proper Tensor dataset\n",
        "  '''\n",
        "  def __init__(self, path):\n",
        "    self.texts = []\n",
        "    with open(path, 'r') as fin:\n",
        "      for line in fin:\n",
        "        self.texts.append(line.strip())\n",
        "    self.n_samples = len(self.texts)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # returns specific item\n",
        "    return self.texts[index] \n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "    # returns dataset length\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj4jILQtXmnt"
      },
      "source": [
        "class TrainingLoop:\n",
        "  '''\n",
        "  Everything related to model training\n",
        "  '''\n",
        "  def __init__( self, model, tokenizer, optimizer, freezeemb=True, \n",
        "                epochs=6, save_path='./models/', **kw):\n",
        "    self.model = model\n",
        "    params = []\n",
        "    for paramname, param in self.model.named_parameters():\n",
        "      if paramname.startswith(\"bert.embeddings.word_embeddings\"):\n",
        "        if not freezeemb:\n",
        "          params.append(param)\n",
        "      else:\n",
        "        params.append(param)\n",
        "    self.optimizer = optimizer(params, **kw)\n",
        "    self.tokenizer = tokenizer\n",
        "    self.epochs = epochs\n",
        "    self.save_path = save_path\n",
        "    self.predicts = None\n",
        "\n",
        "\n",
        "  def train(self, dataloader, eval_dataloader, test_dataloader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model.to(device)\n",
        "    for epoch in range(self.epochs):\n",
        "      self.model.train()\n",
        "      losses = []\n",
        "\n",
        "      for _, batch in enumerate(tqdm(dataloader, position=0, leave=True, desc=f\"Train Epoch Number {epoch+1}\")):\n",
        "        self.model.zero_grad()\n",
        "        X = self.tokenizer(batch['input'], add_special_tokens=True, max_length=512, truncation=True, padding=True)\n",
        "        y = self.tokenizer(batch['response'], add_special_tokens=True, max_length=512, truncation=True, padding=True)\n",
        "        X = torch.tensor(X[\"input_ids\"])\n",
        "        y = torch.tensor(y['input_ids'])\n",
        "        X = X.to(device); y = y.to(device)\n",
        "        outputs = self.model(input_ids=X, decoder_input_ids=y, labels=y) \n",
        "        losses.append(outputs.loss)\n",
        "        outputs.loss.backward()\n",
        "        self.optimizer.step()\n",
        "        # break \n",
        "      logging.info(f'Epoch number: {epoch+1} Train Loss is equal: {sum(losses)/len(losses)}') \n",
        "      self.random_predict(test_dataloader, device, number_of_samples=10)\n",
        "      self.eval(eval_dataloader, epoch, device)\n",
        "      self.save(f\"./models/autoencoder_{epoch}_{datetime.today().strftime('%Y-%m-%d')}.pt\")\n",
        "\n",
        "\n",
        "  def eval(self, dataloader, epoch, device):\n",
        "    self.model.eval()\n",
        "    losses = []\n",
        "    for _, batch in enumerate(tqdm(dataloader, position=0, leave=True, desc=f\"Eval Epoch Number {epoch+1}\")):\n",
        "      with torch.no_grad():\n",
        "        X = self.tokenizer(batch['input'], add_special_tokens=True, max_length=512, truncation=True, padding=True)\n",
        "        y = self.tokenizer(batch['response'], add_special_tokens=True, max_length=512, truncation=True, padding=True)\n",
        "        X = torch.tensor(X[\"input_ids\"])\n",
        "        y = torch.tensor(y['input_ids'])\n",
        "        X = X.to(device); y = y.to(device)\n",
        "        outputs = self.model(input_ids=X, decoder_input_ids=y, labels=y) \n",
        "        \n",
        "        losses.append(outputs.loss)\n",
        "        # break\n",
        "    logging.info(f'Epoch number: {epoch+1} Eval Loss is equal: {sum(losses)/len(losses)}')\n",
        "  \n",
        "  def save(self, save_path='./models/autoencoder.pt'):\n",
        "    logging.info(f'Saving model ...')\n",
        "    torch.save(self.model, save_path)\n",
        "\t\n",
        "  def load(self, save_path='./models/autoencoder.pt'):\n",
        "    logging.info(f'Loading model ...')\n",
        "    self.model = torch.load(save_path)\n",
        "\n",
        "  def random_predict(self, dataloader, device, number_of_samples=10):\n",
        "    counter=0\n",
        "    for sample in dataloader:\n",
        "      counter+=1\n",
        "      _input = self.tokenizer(sample['input'], add_special_tokens=True, max_length=512, padding=True)\n",
        "      _input = torch.tensor(_input['input_ids'])\n",
        "      _input = _input.to(device)\n",
        "      self.model = self.model.to(device)\n",
        "      decoder_start = torch.tensor(30526).to(device)\n",
        "      generated = self.model.generate(_input, decoder_start_token_id=torch.tensor(30526).to(device))\n",
        "      logging.info('Real: '+ sample['response'][0])\n",
        "      logging.info(tokenizer.convert_ids_to_tokens(generated[0]))\n",
        "      if counter>number_of_samples:\n",
        "        break \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "CWwDqSD8ZeB-",
        "outputId": "1ffdb999-957f-4962-f6ea-fc02821c80e2"
      },
      "source": [
        "\n",
        "\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "model.get_encoder().resize_token_embeddings(len(tokenizer))\n",
        "model.get_decoder().resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "optimizer = AdamW\n",
        "kw = {'lr':0.0002, 'weight_decay':0.1}\n",
        "tl = TrainingLoop(model, tokenizer, optimizer, False, **kw)\n",
        "\n",
        "data = read_data()\n",
        "data_samples = data_to_samples(data)\n",
        "bertified_data = bertified(data_samples)\n",
        "train, valid = train_test_split(bertified_data, test_size=0.15, random_state=99)\n",
        "test_data = read_data()\n",
        "test_data_samples = data_to_samples(test_data, True)\n",
        "test = bertified(test_data_samples)\n",
        "\n",
        "train_dataset = PersonaDataset_v1(train)\n",
        "valid_dataset = PersonaDataset_v1(valid)\n",
        "test_dataset = PersonaDataset_v1(test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=6, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tl.train(train_dataloader, valid_dataloader, test_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "# tl.save()\n",
        "# ##################################################\n",
        "# tl.load()\n",
        "# tl.random_predict(test_dataloader, device, number_of_samples=10)\n",
        "# ##################################################\n",
        "# tl.readable_predict(device, print_result=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2de0e0cd9228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-c1444668961d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, eval_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch number: {epoch+1} Train Loss is equal: {sum(losses)/len(losses)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;31m# Just adding the square of the weights to the loss function is *not*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijzZHyrhz9A0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}