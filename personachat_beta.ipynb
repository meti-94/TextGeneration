{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_autoencoder_personachat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3f0d5fbcb2a47eaa63aa34ea290fe86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e48e9ce30a154580aa20c9cdd2c4a403",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91cdfa96a2004ff886b302a1812c3c26",
              "IPY_MODEL_e0925afbe3ca4f1da79f5e598b31f4ba"
            ]
          }
        },
        "e48e9ce30a154580aa20c9cdd2c4a403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91cdfa96a2004ff886b302a1812c3c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecaed19fbb8f487494a4c6b3721d225b",
            "_dom_classes": [],
            "description": "Tokenizing Data Sample ...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f12d384bc1d49b48e255a54691690dd"
          }
        },
        "e0925afbe3ca4f1da79f5e598b31f4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62e2e330a73d402ab6aa61ea7418873a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85/85 [00:00&lt;00:00, 109.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a289efaec91406d9de90aaacb31153a"
          }
        },
        "ecaed19fbb8f487494a4c6b3721d225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f12d384bc1d49b48e255a54691690dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62e2e330a73d402ab6aa61ea7418873a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a289efaec91406d9de90aaacb31153a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "175f87fc49e14cfc85057472e31b668d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76254b1f7c3340bda100cccaab9685fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_48fc5143df26408f9603e6f260863f37",
              "IPY_MODEL_7b981021deb444448520e90d844a4e34"
            ]
          }
        },
        "76254b1f7c3340bda100cccaab9685fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48fc5143df26408f9603e6f260863f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67eb362f906f4f7daec2a9954f1134d5",
            "_dom_classes": [],
            "description": "Tokenizing Data Sample ...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_981eb5756c9e4f5d9666398a922e7ac2"
          }
        },
        "7b981021deb444448520e90d844a4e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9df0faea492945ff92fd61fa1503f223",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15/15 [00:00&lt;00:00, 40.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79ce65e5f0cc431ca4d88231474b1b39"
          }
        },
        "67eb362f906f4f7daec2a9954f1134d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "981eb5756c9e4f5d9666398a922e7ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9df0faea492945ff92fd61fa1503f223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79ce65e5f0cc431ca4d88231474b1b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c03b450bc58e4063949e512c6169d766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_607dd6e3817547e6be7917d269120d5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3151510529ae4833be29c9b57af8e3bc",
              "IPY_MODEL_c986b19ee33849a3874ba16cd350aad1"
            ]
          }
        },
        "607dd6e3817547e6be7917d269120d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3151510529ae4833be29c9b57af8e3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_858c5d96c4634bb886235d8889e6f102",
            "_dom_classes": [],
            "description": "Tokenizing Data Sample ...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_532c4206acc2442d9eb824357e32a91e"
          }
        },
        "c986b19ee33849a3874ba16cd350aad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d5e3b03434d459a9ebda680eea9dedf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:13&lt;00:00,  7.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd01649261d54ae2a62a8c82aaf1c95c"
          }
        },
        "858c5d96c4634bb886235d8889e6f102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "532c4206acc2442d9eb824357e32a91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d5e3b03434d459a9ebda680eea9dedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd01649261d54ae2a62a8c82aaf1c95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff061b608939490088c2a09d32eb220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7786b2980bb41f3971e911c76a50ebe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56cd1906a766432ea32062d9d39c78b4",
              "IPY_MODEL_59b304906a974c7d8d3b20c616a46adf"
            ]
          }
        },
        "c7786b2980bb41f3971e911c76a50ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56cd1906a766432ea32062d9d39c78b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9b06170262a46ce87f5a4f9f4d6e489",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1895,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1895,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d1cc319dc4549e1932e93802ec99f3b"
          }
        },
        "59b304906a974c7d8d3b20c616a46adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7996b5b0fd4a443fbb473819e1ff18b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.82k/? [00:00&lt;00:00, 12.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_486959a99259442cb5e1b9d253350694"
          }
        },
        "d9b06170262a46ce87f5a4f9f4d6e489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d1cc319dc4549e1932e93802ec99f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7996b5b0fd4a443fbb473819e1ff18b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "486959a99259442cb5e1b9d253350694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/TextGeneration/blob/main/personachat_beta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A68SVVaHBzE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnnzmqHDjKyS",
        "cellView": "form"
      },
      "source": [
        "#@title SSH Colab Dropbear\n",
        "import apt, apt.debfile\n",
        "import pathlib, stat, shutil, urllib.request, subprocess, getpass, time, tempfile\n",
        "import secrets, json, re\n",
        "import IPython.utils.io\n",
        "import ipywidgets\n",
        "import socket\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class _NoteProgress(apt.progress.base.InstallProgress, apt.progress.base.AcquireProgress, apt.progress.base.OpProgress):\n",
        "  def __init__(self):\n",
        "    apt.progress.base.InstallProgress.__init__(self)\n",
        "    self._label = ipywidgets.Label()\n",
        "    display(self._label)\n",
        "    self._float_progress = ipywidgets.FloatProgress(min = 0.0, max = 1.0, layout = {'border':'1px solid #118800'})\n",
        "    display(self._float_progress)\n",
        "\n",
        "  def close(self):\n",
        "    self._float_progress.close()\n",
        "    self._label.close()\n",
        "\n",
        "  def fetch(self, item):\n",
        "    self._label.value = \"fetch: \" + item.shortdesc\n",
        "\n",
        "  def pulse(self, owner):\n",
        "    self._float_progress.value = self.current_items / self.total_items\n",
        "    return True\n",
        "\n",
        "  def status_change(self, pkg, percent, status):\n",
        "    self._label.value = \"%s: %s\" % (pkg, status)\n",
        "    self._float_progress.value = percent / 100.0\n",
        "\n",
        "  def update(self, percent=None):\n",
        "    self._float_progress.value = self.percent / 100.0\n",
        "    self._label.value = self.op + \": \" + self.subop\n",
        "\n",
        "  def done(self, item=None):\n",
        "    pass\n",
        "\n",
        "class _MyApt:\n",
        "  def __init__(self):\n",
        "    self._progress = _NoteProgress()\n",
        "    self._cache = apt.Cache(self._progress)\n",
        "\n",
        "  def close(self):\n",
        "    self._cache.close()\n",
        "    self._cache = None\n",
        "    self._progress.close()\n",
        "    self._progress = None\n",
        "\n",
        "  def update_upgrade(self):\n",
        "    self._cache.update()\n",
        "    self._cache.open(None)\n",
        "    self._cache.upgrade()\n",
        "\n",
        "  def commit(self):\n",
        "    self._cache.commit(self._progress, self._progress)\n",
        "    self._cache.clear()\n",
        "\n",
        "  def installPkg(self, *args):\n",
        "    for name in args:\n",
        "      pkg = self._cache[name]\n",
        "      if pkg.is_installed:\n",
        "        print(f\"{name} is already installed\")\n",
        "      else:\n",
        "        pkg.mark_install()\n",
        "\n",
        "  def installDebPackage(self, name):\n",
        "    apt.debfile.DebPackage(name, self._cache).install()\n",
        "\n",
        "  def deleteInstalledPkg(self, *args):\n",
        "    for pkg in self._cache:\n",
        "      if pkg.is_installed:\n",
        "        for name in args:\n",
        "          if pkg.name.startswith(name):\n",
        "            #print(f\"Delete {pkg.name}\")\n",
        "            pkg.mark_delete()\n",
        "\n",
        "def _download(url, path):\n",
        "  try:\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      with open(path, 'wb') as outfile:\n",
        "        shutil.copyfileobj(response, outfile)\n",
        "  except:\n",
        "    print(\"Failed to download \", url)\n",
        "    raise\n",
        "\n",
        "  return True\n",
        "\n",
        "def _setupssh():\n",
        "  #Inpur Username\n",
        "  print(\"Create a username :\")\n",
        "  user_name = input()\n",
        "  subprocess.run([\"useradd\", \"-s\", \"/bin/bash\", \"-m\", user_name])\n",
        "  subprocess.run([\"adduser\", user_name, \"sudo\"], check = True)\n",
        "  clear_output()\n",
        "\n",
        "  #Inpur Password\n",
        "  print(\"Create a password :\")\n",
        "  user_password = getpass.getpass()\n",
        "  subprocess.run([\"chpasswd\"], input = f\"{user_name}:{user_password}\", universal_newlines = True)\n",
        "  clear_output()\n",
        "\n",
        "  #Set your ngrok Authtoken.\n",
        "  print(\"Copy & paste your tunnel authtoken from https://dashboard.ngrok.com/auth\")\n",
        "  print(\"(You need to sign up for ngrok and login.)\")\n",
        "  ngrok_token = getpass.getpass()\n",
        "  clear_output()\n",
        "\n",
        "  #Set your ngrok region.\n",
        "  print(\"Select your ngrok region :\")\n",
        "  print(\"us - United States (Ohio)\")\n",
        "  print(\"eu - Europe (Frankfurt)\")\n",
        "  print(\"ap - Asia/Pacific (Singapore)\")\n",
        "  print(\"au - Australia (Sydney)\")\n",
        "  print(\"sa - South America (Sao Paulo)\")\n",
        "  print(\"jp - Japan (Tokyo)\")\n",
        "  print(\"in - India (Mumbai)\")\n",
        "  ngrok_region = input()\n",
        "  clear_output()\n",
        "\n",
        "  #SSH Dropbear\n",
        "  my_apt = _MyApt()\n",
        "  my_apt.installPkg(\"dropbear\")\n",
        "  my_apt.commit()\n",
        "  my_apt.close()\n",
        "\n",
        "  #Set Dropbear\n",
        "  f = open(\"../etc/default/dropbear\", \"w\")\n",
        "  f.write(\"\"\"# the TCP port that Dropbear listens on\n",
        "DROPBEAR_PORT=443\n",
        "\n",
        "# any additional arguments for Dropbear\n",
        "DROPBEAR_EXTRA_ARGS=\n",
        "\n",
        "# specify an optional banner file containing a message to be\n",
        "# sent to clients before they connect, such as \"/etc/issue.net\"\n",
        "DROPBEAR_BANNER=\"\"\n",
        "\n",
        "# RSA hostkey file (default: /etc/dropbear/dropbear_rsa_host_key)\n",
        "#DROPBEAR_RSAKEY=\"/etc/dropbear/dropbear_rsa_host_key\"\n",
        "\n",
        "# DSS hostkey file (default: /etc/dropbear/dropbear_dss_host_key)\n",
        "#DROPBEAR_DSSKEY=\"/etc/dropbear/dropbear_dss_host_key\"\n",
        "\n",
        "# ECDSA hostkey file (default: /etc/dropbear/dropbear_ecdsa_host_key)\n",
        "#DROPBEAR_ECDSAKEY=\"/etc/dropbear/dropbear_ecdsa_host_key\"\n",
        "\n",
        "# Receive window size - this is a tradeoff between memory and\n",
        "# network performance\n",
        "DROPBEAR_RECEIVE_WINDOW=65536\n",
        "\"\"\")\n",
        "  f.close()\n",
        "\n",
        "  #SSH Service Restart\n",
        "  subprocess.run([\"service\", \"dropbear\", \"restart\"])\n",
        "\n",
        "  #Root Password\n",
        "  root_password = user_password\n",
        "  subprocess.run([\"chpasswd\"], input = f\"root:{root_password}\", universal_newlines = True)\n",
        "\n",
        "  # Ngrok Tunnel\n",
        "  if not os.path.exists('ngrok.zip'):\n",
        "    _download(\"https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\", \"ngrok.zip\")\n",
        "    shutil.unpack_archive(\"ngrok.zip\")\n",
        "    pathlib.Path(\"ngrok\").chmod(stat.S_IXUSR)\n",
        "\n",
        "  subprocess.run([\"./ngrok\", \"authtoken\", ngrok_token])\n",
        "  ngrok_proc = subprocess.Popen([\"./ngrok\", \"tcp\", \"-region\", ngrok_region, \"443\"])\n",
        "  time.sleep(2)\n",
        "\n",
        "  with urllib.request.urlopen(\"http://localhost:4040/api/tunnels\") as response:\n",
        "    url = json.load(response)['tunnels'][0]['public_url']\n",
        "    m = re.match(\"tcp://(.+):(\\d+)\", url)\n",
        "\n",
        "  hostname = m.group(1)\n",
        "  port = m.group(2)\n",
        "  \n",
        "  msg = \"\"\n",
        "  msg += \"=\"*48 + \"\\n\"\n",
        "  msg += \"Command to connect to the ssh server:\\n\"\n",
        "  msg += f\"ssh -p {port} {user_name}@{socket.gethostbyname(hostname)}\\n\"\n",
        "  msg += \"=\"*48 + \"\\n\"\n",
        "  msg += \"SSH Login NetMod and Others:\\n\"\n",
        "  msg += f\"Host            : {socket.gethostbyname(hostname)}\\n\"\n",
        "  msg += f\"Port (Dropbear) : {port}\\n\"\n",
        "  msg += f\"Username        : {user_name}\\n\"\n",
        "  msg += f\"Password        : {user_password}\\n\"\n",
        "  msg += \"=\"*48 + \"\\n\"\n",
        "  return msg\n",
        "\n",
        "def startColab():\n",
        "  msg = _setupssh()\n",
        "  print(msg)\n",
        "\n",
        "startColab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdM9KHPaRNmD"
      },
      "source": [
        "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "!tar -xf  simple-examples.tgz\n",
        "!mkdir data\n",
        "!mv /content/simple-examples/data/ptb.train.txt data/\n",
        "!mv /content/simple-examples/data/ptb.valid.txt data/\n",
        "!mv /content/simple-examples/data/ptb.test.txt data/\n",
        "!rm -rf ./simple_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B71K5lC_Xnyg",
        "outputId": "508c6b55-9c6d-4b69-b765-d67241a016ce"
      },
      "source": [
        "!pip install \"ray[tune]\" transformers datasets==1.1.2\n",
        "# !pip install transformers\n",
        "!ray install-nightly\n",
        "!pip install rouge_score\n",
        "!pip install -U ray\n",
        "# !pip install -U transformers datasets\n",
        "!pip install tensorboardX\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray[tune]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/14/15d0f0aec20a4674a996429160565a071688f27f49f789327ebed8188ffb/ray-1.2.0-cp37-cp37m-manylinux2014_x86_64.whl (47.5MB)\n",
            "\u001b[K     |████████████████████████████████| 47.5MB 63kB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 38.0MB/s \n",
            "\u001b[?25hCollecting datasets==1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/f4/2a3d6aee93ae7fce6c936dda2d7f534ad5f044a21238f85e28f0b205adf0/datasets-1.1.2-py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 36.3MB/s \n",
            "\u001b[?25hCollecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Collecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/d6/b952f11b29c3a0cbec5620de3c4260cecd8c4329d83e91587edb48691e15/opencensus-0.7.12-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.10.1)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.32.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.12.4)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.0.12)\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Collecting redis>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 33.3MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/a6/52515fe345fad06a567feb0ee3841bface31f00e1e0dcd401aa16b3fc648/py_spy-0.3.5-py2.py3-none-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 37.7MB/s \n",
            "\u001b[?25hCollecting tensorboardX; extra == \"tune\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.1.5)\n",
            "Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.1.2) (0.3.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.1.2) (0.70.11.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.1.2) (3.0.0)\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/33/290cea35b09c80b4634773ad5572a8030a87b5d39736719f698f521d2a13/hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.5MB/s \n",
            "\u001b[?25hCollecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->ray[tune]) (54.2.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (20.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.28.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp37-none-any.whl size=12621 sha256=09316e583312dbc36a82aeb238ba4695b83caa4e29b204e139b6b992627a0832\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "Successfully built gpustat\n",
            "Installing collected packages: hiredis, async-timeout, aioredis, opencensus-context, opencensus, colorama, colorful, blessings, gpustat, multidict, yarl, aiohttp, aiohttp-cors, redis, py-spy, tensorboardX, ray, tokenizers, sacremoses, transformers, xxhash, datasets\n",
            "Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 datasets-1.1.2 gpustat-0.6.0 hiredis-2.0.0 multidict-5.1.0 opencensus-0.7.12 opencensus-context-0.1.2 py-spy-0.3.5 ray-1.2.0 redis-3.5.3 sacremoses-0.0.45 tensorboardX-2.2 tokenizers-0.10.2 transformers-4.5.1 xxhash-2.0.2 yarl-1.6.3\n",
            "Running: /usr/bin/python3 -m pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl.\n",
            "Collecting ray==2.0.0.dev0\n",
            "\u001b[?25l  Downloading https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl (49.4MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4MB 98kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (1.0.2)\n",
            "Collecting protobuf>=3.15.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/4e/de63de3cd9a83d3c1753a4566b11fc9d90b845f2448a132cfd36d3cb3cd1/protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: aioredis in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: opencensus in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.7.12)\n",
            "Requirement already satisfied, skipping upgrade: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.3.5)\n",
            "Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (3.5.3)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (3.7.4.post0)\n",
            "Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: gpustat in /usr/local/lib/python3.7/dist-packages (from ray==2.0.0.dev0) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.15.3->ray==2.0.0.dev0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis->ray==2.0.0.dev0) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray==2.0.0.dev0) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==2.0.0.dev0) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==2.0.0.dev0) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray==2.0.0.dev0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray==2.0.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray==2.0.0.dev0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray==2.0.0.dev0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==2.0.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==2.0.0.dev0) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==2.0.0.dev0) (5.1.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==2.0.0.dev0) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==2.0.0.dev0) (1.7)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==2.0.0.dev0) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==2.0.0.dev0) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==2.0.0.dev0) (0.4.8)\n",
            "Installing collected packages: protobuf, ray\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: ray 1.2.0\n",
            "    Uninstalling ray-1.2.0:\n",
            "      Successfully uninstalled ray-1.2.0\n",
            "Successfully installed protobuf-3.15.8 ray-2.0.0.dev0\n",
            "\u001b[0mCollecting rouge_score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n",
            "Requirement already up-to-date: ray in /usr/local/lib/python3.7/dist-packages (2.0.0.dev0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray) (3.5.3)\n",
            "Requirement already satisfied, skipping upgrade: aioredis in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray) (0.3.5)\n",
            "Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: opencensus in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.12)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.4.post0)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.7/dist-packages (from ray) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.15.8)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: gpustat in /usr/local/lib/python3.7/dist-packages (from ray) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (1.26.3)\n",
            "Requirement already satisfied, skipping upgrade: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (5.1.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.7)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.15.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pr76H8apmK0",
        "outputId": "2da081d8-e057-4495-c121-6b667d4f900e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import datasets\n",
        "datasets.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.1.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-nJAxtd0TQA",
        "outputId": "fcbdba07-5c40-4a17-83f8-7f1d2560428d"
      },
      "source": [
        "!wget https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
        "!mkdir models"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 13:34:49--  https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.254\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209850483 (200M) [application/json]\n",
            "Saving to: ‘personachat_self_original.json’\n",
            "\n",
            "personachat_self_or 100%[===================>] 200.13M  35.5MB/s    in 6.3s    \n",
            "\n",
            "2021-04-21 13:34:56 (31.8 MB/s) - ‘personachat_self_original.json’ saved [209850483/209850483]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iivSufj9QhvS",
        "outputId": "0cdf6ac6-76a4-4e8b-b271-ea3786ade048"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S5ZszffTUhl"
      },
      "source": [
        "import ray\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EncoderDecoderModel, BertTokenizer, BertModel, BertConfig\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import logging\n",
        "import datasets\n",
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVUFk1dqSTbG"
      },
      "source": [
        "SPECIAL_TOKENS = [\"<bos>\", \"<eos>\", \"<persona>\", \"<speaker1>\", \"<speaker2>\", \"<pad>\"]\n",
        "\n",
        "ATTR_TO_SPECIAL_TOKEN = {'bos_token': '<bos>', 'eos_token': '<eos>', 'pad_token': '<pad>',\n",
        "                         'additional_special_tokens': ['<speaker1>', '<speaker2>', '<persona>']}\n",
        "\n",
        "encoder_max_length=512\n",
        "decoder_max_length=128\n",
        "\n",
        "def read_data(data_json_path='/content/personachat_self_original.json'):\n",
        "  with open(data_json_path) as json_file:\n",
        "    data_dict = json.load(json_file)\n",
        "  return data_dict\n",
        "\n",
        "def data_to_samples(data_dict, test=False):\n",
        "  samples=[]\n",
        "  for dialogue in (data_dict['train'] if test==False else data_dict['valid']):\n",
        "    original_persona = dialogue['personality']\n",
        "    \n",
        "    for item in dialogue['utterances']:\n",
        "      original_persona = [original_persona[-1]] + original_persona[:-1]\n",
        "      history = item['history']\n",
        "      response = item['candidates'][-1]\n",
        "      samples.append({\n",
        "          'persona':original_persona,\n",
        "          'history':history,\n",
        "          'response':response\n",
        "      })\n",
        "  return samples\n",
        "  \n",
        "def bertified(samples):\n",
        "  bertified_data = []\n",
        "  for item in samples:\n",
        "    persona = ' <persona> '.join(item['persona'])\n",
        "    persona = '<bos> ' + persona\n",
        "    history = ''\n",
        "    speakers = [\" <speaker1> \", \" <speaker2> \"]\n",
        "    speaker = 0\n",
        "    for hst in item['history'][::-1]:\n",
        "      history = speakers[speaker] + hst + history\n",
        "      speaker = 1 - speaker\n",
        "    response = '<speaker2> ' + item['response'] + ' <eos>'\n",
        "    bertified_data.append({\n",
        "          'persona':persona.replace('  ', ' '),\n",
        "          'history':history.replace('  ', ' '),\n",
        "          'input': persona.replace('  ', ' ')+' '+history.replace('  ', ' '), \n",
        "          'response':response.replace('  ', ' ')\n",
        "      })\n",
        "  return bertified_data\n",
        "\n",
        "def bertified_to_model_food(bertified_data, tokenizer):\n",
        "    model_food = []\n",
        "    pbar = tqdm(bertified_data)\n",
        "    pbar.set_description('Tokenizing Data Sample ...')\n",
        "    for item in pbar:\n",
        "        inputs = tokenizer(item['input'], add_special_tokens=True, max_length=encoder_max_length, truncation=True, padding=\"max_length\")\n",
        "        outputs = tokenizer(item['response'], add_special_tokens=True, max_length=decoder_max_length, truncation=True, padding=\"max_length\")\n",
        "        _item = {}\n",
        "        _item[\"input_ids\"] = inputs.input_ids\n",
        "        _item[\"attention_mask\"] = inputs.attention_mask\n",
        "        _item[\"decoder_input_ids\"] = outputs.input_ids\n",
        "        _item[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "        _item[\"labels\"] = outputs.input_ids.copy()\n",
        "        model_food.append(_item)\n",
        "    return model_food "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrcvjwRn1zCl"
      },
      "source": [
        "class PersonaDataset_v3(Dataset):\n",
        "  '''\n",
        "      Convert Data to proper Tensor dataset\n",
        "  '''\n",
        "  def __init__(self, samples):\n",
        "    self.samples = samples\n",
        "    self.n_samples = len(self.samples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # returns specific item\n",
        "    return self.samples[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "c3f0d5fbcb2a47eaa63aa34ea290fe86",
            "e48e9ce30a154580aa20c9cdd2c4a403",
            "91cdfa96a2004ff886b302a1812c3c26",
            "e0925afbe3ca4f1da79f5e598b31f4ba",
            "ecaed19fbb8f487494a4c6b3721d225b",
            "8f12d384bc1d49b48e255a54691690dd",
            "62e2e330a73d402ab6aa61ea7418873a",
            "3a289efaec91406d9de90aaacb31153a",
            "175f87fc49e14cfc85057472e31b668d",
            "76254b1f7c3340bda100cccaab9685fe",
            "48fc5143df26408f9603e6f260863f37",
            "7b981021deb444448520e90d844a4e34",
            "67eb362f906f4f7daec2a9954f1134d5",
            "981eb5756c9e4f5d9666398a922e7ac2",
            "9df0faea492945ff92fd61fa1503f223",
            "79ce65e5f0cc431ca4d88231474b1b39",
            "c03b450bc58e4063949e512c6169d766",
            "607dd6e3817547e6be7917d269120d5d",
            "3151510529ae4833be29c9b57af8e3bc",
            "c986b19ee33849a3874ba16cd350aad1",
            "858c5d96c4634bb886235d8889e6f102",
            "532c4206acc2442d9eb824357e32a91e",
            "1d5e3b03434d459a9ebda680eea9dedf",
            "fd01649261d54ae2a62a8c82aaf1c95c"
          ]
        },
        "id": "CUUvf3MRpWwH",
        "outputId": "ccb7cde8-70ef-45d7-8c87-a5caf5668823"
      },
      "source": [
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"prajjwal1/bert-tiny\", \"prajjwal1/bert-tiny\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "model.get_encoder().resize_token_embeddings(len(tokenizer))\n",
        "model.get_decoder().resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "data = read_data()\n",
        "data_samples = data_to_samples(data)\n",
        "bertified_data = bertified(data_samples)\n",
        "train, valid = train_test_split(bertified_data[:100], test_size=0.15, random_state=99)\n",
        "train = bertified_to_model_food(train, tokenizer)\n",
        "valid = bertified_to_model_food(valid, tokenizer)\n",
        "test_data = read_data()\n",
        "test_data_samples = data_to_samples(test_data, True)\n",
        "test = bertified(test_data_samples)\n",
        "test = bertified_to_model_food(test[:100], tokenizer)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/tokenizer_config.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /prajjwal1/bert-tiny/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3f0d5fbcb2a47eaa63aa34ea290fe86",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "175f87fc49e14cfc85057472e31b668d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c03b450bc58e4063949e512c6169d766",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yqX5XhB0_i4"
      },
      "source": [
        "# train_dataset = PersonaDataset_v3(list(zip(*map(one_line_tokenizer, tqdm(train)))))\n",
        "train_dataset = PersonaDataset_v3(train[:100])\n",
        "valid_dataset = PersonaDataset_v3(valid[:100])\n",
        "test_dataset = PersonaDataset_v3(test[:100])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXfk_c5-qhAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "ff061b608939490088c2a09d32eb220a",
            "c7786b2980bb41f3971e911c76a50ebe",
            "56cd1906a766432ea32062d9d39c78b4",
            "59b304906a974c7d8d3b20c616a46adf",
            "d9b06170262a46ce87f5a4f9f4d6e489",
            "7d1cc319dc4549e1932e93802ec99f3b",
            "7996b5b0fd4a443fbb473819e1ff18b7",
            "486959a99259442cb5e1b9d253350694"
          ]
        },
        "outputId": "5f9daf1c-0e2b-43ae-cd9c-22ea802e4555"
      },
      "source": [
        "rouge = datasets.load_metric(\"rouge\")\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/metrics/rouge/rouge.py HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
            "DEBUG:urllib3.connectionpool:https://raw.githubusercontent.com:443 \"HEAD /huggingface/datasets/1.1.2/metrics/rouge/rouge.py HTTP/1.1\" 200 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140211271044816 on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "INFO:filelock:Lock 140211271044816 acquired on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443\n",
            "DEBUG:urllib3.connectionpool:https://raw.githubusercontent.com:443 \"GET /huggingface/datasets/1.1.2/metrics/rouge/rouge.py HTTP/1.1\" 200 1895\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff061b608939490088c2a09d32eb220a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1895.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140211271044816 on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "INFO:filelock:Lock 140211271044816 released on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:https://raw.githubusercontent.com:443 \"HEAD /huggingface/datasets/1.1.2/metrics/rouge/dataset_infos.json HTTP/1.1\" 404 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140209947123664 on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "INFO:filelock:Lock 140209947123664 acquired on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "DEBUG:filelock:Attempting to release lock 140209947123664 on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n",
            "INFO:filelock:Lock 140209947123664 released on /root/.cache/huggingface/datasets/336a0cbdd138e0d6e1361544ed2c56565192be45b5398cd55ac988d4b3fd1455.a89f1fa0750909f2d149b1ecabc808fb66cb865c94bb8bbb135c55deb50da2d7.py.lock\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nxdqTEBzorK"
      },
      "source": [
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "# model.config.max_length = 142\n",
        "# model.config.min_length = 56\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.early_stopping = True\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGldq9Avo7Ki"
      },
      "source": [
        "batch_size = 128\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/models/\",\n",
        "    do_eval=True,\n",
        "    # do_train = True,\n",
        "    # do_train = True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    \n",
        "    eval_steps=2,\n",
        "    logging_steps=2,\n",
        "\n",
        "\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "\n",
        "    predict_with_generate=True,\n",
        "    \n",
        "    \n",
        "    fp16=True, \n",
        "    \n",
        "    save_strategy = 'steps',\n",
        "    save_steps=35,\n",
        "    save_total_limit = 2\n",
        "    \n",
        "    # logging_steps=1000,\n",
        "    # save_steps=500,\n",
        "    # eval_steps=7500,\n",
        "    # warmup_steps=2000,\n",
        "    # save_total_limit=3,\n",
        ")\n",
        "# instantiate trainer\n",
        "def model_init():\n",
        "    return model\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# trainer.train()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijzZHyrhz9A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61745756-7ba9-4406-cb9f-feee573c98a5"
      },
      "source": [
        "# from ray import tune\n",
        "# from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "# from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "\n",
        "trainer.hyperparameter_search(\n",
        "    direction=\"maximize\", \n",
        "    backend=\"ray\", \n",
        "    n_trials=2, # number of trials\n",
        "    # n_jobs=2  # number of parallel jobs, if multiple GPUs\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:ray.tune.tune:Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`.\n",
            "2021-04-21 13:36:38,949\tINFO services.py:1264 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 3.2/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
            "+------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------+\n",
            "| Trial name             | status   | loc   |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |\n",
            "|------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------|\n",
            "| _objective_9b23c_00000 | RUNNING  |       |     5.61152e-06 |                  5 |                            64 | 8.15396 |\n",
            "| _objective_9b23c_00001 | PENDING  |       |     1.56207e-05 |                  2 |                            16 | 7.08379 |\n",
            "+------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-04-21 13:36:43.401103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
            "+------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------+\n",
            "| Trial name             | status   | loc   |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |\n",
            "|------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------|\n",
            "| _objective_9b23c_00000 | RUNNING  |       |     5.61152e-06 |                  5 |                            64 | 8.15396 |\n",
            "| _objective_9b23c_00001 | PENDING  |       |     1.56207e-05 |                  2 |                            16 | 7.08379 |\n",
            "+------------------------+----------+-------+-----------------+--------------------+-------------------------------+---------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00000:\n",
            "  date: 2021-04-21_13-36-50\n",
            "  done: false\n",
            "  eval_loss: 10.923986434936523\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.5453\n",
            "  eval_samples_per_second: 9.707\n",
            "  experiment_id: 72d13c8f121843c3ab99f7550cdcad17\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 494\n",
            "  time_since_restore: 8.774749755859375\n",
            "  time_this_iter_s: 8.774749755859375\n",
            "  time_total_s: 8.774749755859375\n",
            "  timestamp: 1619012210\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 9b23c_00000\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "== Status ==\n",
            "Memory usage on this node: 4.3/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
            "+------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "| Trial name             | status   | loc            |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |   objective |\n",
            "|------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------|\n",
            "| _objective_9b23c_00000 | RUNNING  | 172.28.0.2:494 |     5.61152e-06 |                  5 |                            64 | 8.15396 |           0 |\n",
            "| _objective_9b23c_00001 | PENDING  |                |     1.56207e-05 |                  2 |                            16 | 7.08379 |             |\n",
            "+------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00000:\n",
            "  date: 2021-04-21_13-36-56\n",
            "  done: false\n",
            "  eval_loss: 10.807398796081543\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.4676\n",
            "  eval_samples_per_second: 10.221\n",
            "  experiment_id: 72d13c8f121843c3ab99f7550cdcad17\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 494\n",
            "  time_since_restore: 14.477831840515137\n",
            "  time_this_iter_s: 2.9294886589050293\n",
            "  time_total_s: 14.477831840515137\n",
            "  timestamp: 1619012216\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 9b23c_00000\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "== Status ==\n",
            "Memory usage on this node: 4.3/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
            "+------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "| Trial name             | status   | loc            |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |   objective |\n",
            "|------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------|\n",
            "| _objective_9b23c_00000 | RUNNING  | 172.28.0.2:494 |     5.61152e-06 |                  5 |                            64 | 8.15396 |           0 |\n",
            "| _objective_9b23c_00001 | PENDING  |                |     1.56207e-05 |                  2 |                            16 | 7.08379 |             |\n",
            "+------------------------+----------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00000:\n",
            "  date: 2021-04-21_13-37-02\n",
            "  done: false\n",
            "  eval_loss: 10.700596809387207\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.5078\n",
            "  eval_samples_per_second: 9.948\n",
            "  experiment_id: 72d13c8f121843c3ab99f7550cdcad17\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 494\n",
            "  time_since_restore: 20.268656015396118\n",
            "  time_this_iter_s: 2.9281206130981445\n",
            "  time_total_s: 20.268656015396118\n",
            "  timestamp: 1619012222\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 9b23c_00000\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00000:\n",
            "  date: 2021-04-21_13-37-02\n",
            "  done: true\n",
            "  eval_loss: 10.700596809387207\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.5078\n",
            "  eval_samples_per_second: 9.948\n",
            "  experiment_id: 72d13c8f121843c3ab99f7550cdcad17\n",
            "  experiment_tag: 0_learning_rate=5.6115e-06,num_train_epochs=5,per_device_train_batch_size=64,seed=8.154\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 494\n",
            "  time_since_restore: 20.268656015396118\n",
            "  time_this_iter_s: 2.9281206130981445\n",
            "  time_total_s: 20.268656015396118\n",
            "  timestamp: 1619012222\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 9b23c_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m Error in atexit._run_exitfuncs:\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/history.py\", line 786, in writeout_cache\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m     self._writeout_input_cache(conn)\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/history.py\", line 770, in _writeout_input_cache\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m     (self.session_number,)+line)\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 140337858459392 and this is thread id 140342262105984.\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m 2021-04-21 13:37:04.962882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00001:\n",
            "  date: 2021-04-21_13-37-11\n",
            "  done: false\n",
            "  eval_loss: 10.923986434936523\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.5591\n",
            "  eval_samples_per_second: 9.621\n",
            "  experiment_id: 39a3a95d87ac474d8c529db81a36dd12\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 493\n",
            "  time_since_restore: 8.163029670715332\n",
            "  time_this_iter_s: 8.163029670715332\n",
            "  time_total_s: 8.163029670715332\n",
            "  timestamp: 1619012231\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 9b23c_00001\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.2/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
            "+------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "| Trial name             | status     | loc            |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |   objective |\n",
            "|------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------|\n",
            "| _objective_9b23c_00001 | RUNNING    | 172.28.0.2:493 |     1.56207e-05 |                  2 |                            16 | 7.08379 |           0 |\n",
            "| _objective_9b23c_00000 | TERMINATED |                |     5.61152e-06 |                  5 |                            64 | 8.15396 |           0 |\n",
            "+------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "Result for _objective_9b23c_00001:\n",
            "  date: 2021-04-21_13-37-18\n",
            "  done: false\n",
            "  eval_loss: 10.302577018737793\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.519\n",
            "  eval_samples_per_second: 9.875\n",
            "  experiment_id: 39a3a95d87ac474d8c529db81a36dd12\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 493\n",
            "  time_since_restore: 14.5555260181427\n",
            "  time_this_iter_s: 2.191922903060913\n",
            "  time_total_s: 14.5555260181427\n",
            "  timestamp: 1619012238\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 9b23c_00001\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.2/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
            "+------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "| Trial name             | status     | loc            |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |   objective |\n",
            "|------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------|\n",
            "| _objective_9b23c_00001 | RUNNING    | 172.28.0.2:493 |     1.56207e-05 |                  2 |                            16 | 7.08379 |           0 |\n",
            "| _objective_9b23c_00000 | TERMINATED |                |     5.61152e-06 |                  5 |                            64 | 8.15396 |           0 |\n",
            "+------------------------+------------+----------------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m <IPython.core.display.HTML object>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 13:37:22,638\tINFO tune.py:549 -- Total run time: 41.15 seconds (40.76 seconds for the tuning loop).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for _objective_9b23c_00001:\n",
            "  date: 2021-04-21_13-37-22\n",
            "  done: true\n",
            "  eval_loss: 10.064268112182617\n",
            "  eval_rouge2_fmeasure: 0.0\n",
            "  eval_rouge2_precision: 0.0\n",
            "  eval_rouge2_recall: 0.0\n",
            "  eval_runtime: 1.5345\n",
            "  eval_samples_per_second: 9.775\n",
            "  experiment_id: 39a3a95d87ac474d8c529db81a36dd12\n",
            "  experiment_tag: 1_learning_rate=1.5621e-05,num_train_epochs=2,per_device_train_batch_size=16,seed=7.0838\n",
            "  hostname: 9a16a58603ea\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  objective: 0.0\n",
            "  pid: 493\n",
            "  time_since_restore: 18.793177843093872\n",
            "  time_this_iter_s: 2.0758109092712402\n",
            "  time_total_s: 18.793177843093872\n",
            "  timestamp: 1619012242\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 9b23c_00001\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.2/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.35 GiB heap, 0.0/3.68 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/_objective_2021-04-21_13-36-41\n",
            "Number of trials: 2/2 (2 TERMINATED)\n",
            "+------------------------+------------+-------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "| Trial name             | status     | loc   |   learning_rate |   num_train_epochs |   per_device_train_batch_size |    seed |   objective |\n",
            "|------------------------+------------+-------+-----------------+--------------------+-------------------------------+---------+-------------|\n",
            "| _objective_9b23c_00000 | TERMINATED |       |     5.61152e-06 |                  5 |                            64 | 8.15396 |           0 |\n",
            "| _objective_9b23c_00001 | TERMINATED |       |     1.56207e-05 |                  2 |                            16 | 7.08379 |           0 |\n",
            "+------------------------+------------+-------+-----------------+--------------------+-------------------------------+---------+-------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m Error in atexit._run_exitfuncs:\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/history.py\", line 786, in writeout_cache\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m     self._writeout_input_cache(conn)\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/history.py\", line 770, in _writeout_input_cache\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m     (self.session_number,)+line)\n",
            "\u001b[2m\u001b[36m(pid=493)\u001b[0m sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139631387977472 and this is thread id 139635791624064.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='9b23c_00000', objective=0.0, hyperparameters={'learning_rate': 5.61151641533451e-06, 'num_train_epochs': 5, 'seed': 8.153956804780389, 'per_device_train_batch_size': 64})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOZ5tb-Gk_RB"
      },
      "source": [
        "!rm -rf /root/ray_results/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQkxXQP7mPMG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}